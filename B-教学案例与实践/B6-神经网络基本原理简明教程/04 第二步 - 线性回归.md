Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

## <center>第二步</center>

# <center>线性回归</center>

用线性回归作为学习神经网络的起点，是一个非常好的选择，因为线性回归问题本身比较容易理解，在它的基础上，逐步的增加一些新的知识点，会形成一条比较平缓的学习曲线，或者说是迈向神经网络的第一个小台阶。

单层的神经网络，可以完成一些线性的工作，比如拟合一条直线，这用一个神经元就可以实现。当这个神经元只接收一个输入时，就是单变量线性回归，可以在二维平面上用视觉表现。当可以接收多个变量输入时，叫做多变量线性回归，此时视觉表现就比较困难了，通常我们会用变量两两组对的方式来表现。

4. 单变量线性回归
   1. 最小二乘法
   2. 梯度下降法
   3. 神经网络法
   4. 梯度下降的三种形式
   5. 实现逻辑非门
5. 多变量线性回归
   1. 正规方程法
   2. 神经网络法
   3. 样本特征数据归一化
   4. 归一化的后遗症
   5. 正确的推理方法
   6. 归一化样本标签值